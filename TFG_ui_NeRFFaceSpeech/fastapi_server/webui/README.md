# NeRFFaceSpeech Web UI 使用指南

## 📋 目录

- [概述](#概述)
- [快速开始](#快速开始)
- [功能模块](#功能模块)
- [页面说明](#页面说明)
- [常见问题](#常见问题)
- [技术架构](#技术架构)

---

## 概述

NeRFFaceSpeech Web UI 是一个基于 FastAPI + HTML/CSS/JavaScript 的完整 Web 应用系统，提供视频生成、人机对话、模型训练等核心功能。

### 核心特性

- 🎬 **视频生成**：文本输入 → LLM 生成回复 → TTS 语音合成 → NeRF 视频生成
- 💬 **人机对话**：实时对话，支持 LLM 问答和 TTS 语音回复
- 🎓 **模型训练**：StyleNeRF 模型微调训练，完整的训练监控和管理
- 🖥️ **后端监控**：实时查看后端日志、任务状态和系统信息
- 💾 **数据管理**：数据库内容查看和管理

### 技术栈

- **后端**：FastAPI (Python)
- **前端**：HTML5 + CSS3 + JavaScript (原生)
- **存储**：SQLite 数据库
- **视频处理**：FFmpeg (H.264/AAC 转码)

---

## 快速开始

### 🚀 一键启动（推荐）

```bash
cd fastapi_server
python start.py
```

启动脚本会自动：
1. 设置必要的环境变量
2. 启动后端服务器（FastAPI，端口 8000）
3. 启动前端服务器（HTTP，端口 7860）
4. 打开浏览器显示选择页面

### 手动启动

#### 1. 设置环境变量

```bash
export PIP_INDEX_URL=https://pypi.tuna.tsinghua.edu.cn/simple
export TORCH_HOME=/root/autodl-tmp/weights
export HF_ENDPOINT=https://hf-mirror.com
export HF_HOME=/root/autodl-tmp/Hugging_Face
```

#### 2. 启动后端服务器

```bash
cd fastapi_server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

后端地址：`http://localhost:8000/`
- 根路径：后端显示屏（日志输出）
- API 文档：`http://localhost:8000/docs`

#### 3. 启动前端服务器

```bash
cd fastapi_server
python simple_web.py
```

前端地址：`http://localhost:7860/`
- 根路径：选择页面（开发者入口）
- 前端主页：`http://localhost:7860/index.html`

---

## 功能模块

### 🎬 视频生成

**功能**：从文本生成 NeRF 视频

**流程**：
1. 输入文本（例如："你好，请简要介绍一下人工智能"）
2. 选择角色（`ayanami` 或 `Aerith`）
3. 选择模型（从下拉菜单选择 `.pkl` 模型文件）
4. 点击"🚀 开始生成视频"
5. 等待生成完成（通常需要 5-10 分钟）

**特性**：
- 实时进度显示（LLM → TTS → NeRF → 转码）
- 视频自动转码为浏览器兼容格式（H.264/AAC）
- 历史记录管理（查看、重播、下载）
- 视频信息显示（编码、分辨率、时长等）

**注意事项**：
- 视频生成需要较长时间，请耐心等待
- 生成过程中可以点击"取消生成"按钮中止
- 生成的视频会自动保存到服务器

### 💬 人机对话

**功能**：与 AI 进行实时对话，支持文本和语音

**操作**：
- **文本对话**：在输入框输入问题，按 `Enter` 发送
- **语音回复**：AI 回复会自动播放语音（可关闭）
- **对话管理**：新建对话、查看历史、导出对话记录

**特性**：
- 流式输出（AI 回复逐字显示）
- 自动语音播放
- 对话历史保存
- 消息状态显示（发送中、已送达、错误）

### 🎓 模型训练

**功能**：StyleNeRF 模型微调训练

**配置**：
- 训练数据路径
- 学习率、批量大小、训练轮数
- 数据增强选项
- 基础模型选择

**监控**：
- 实时训练日志
- 训练进度条
- 损失曲线图
- GPU 使用率显示
- 训练时间统计

**管理**：
- 训练任务列表（进行中/已完成/失败）
- 暂停/恢复训练
- 停止训练
- 训练历史记录

### 🖥️ 后端监控

**功能**：实时查看后端输出、日志和调试信息

**页面**：
- **日志输出**：显示最近 1000 条日志（自动删除多余的，节省内存）
- **数据库内容**：查看数据库中的设置和视频生成记录

**操作**：
- 刷新日志
- 清空显示
- 自动滚动
- 过滤 HTTP 请求日志

---

## 页面说明

### 🚪 选择页面 (`start.html`)

**功能**：开发者模式入口

**操作**：
- 点击"后端显示屏" → 打开后端输出页面
- 点击"前端应用" → 进入前端主页
- 右上角可切换主题和字体设置

**访问**：`http://localhost:7860/`

### 🏠 前端主页 (`index.html`)

**功能**：三个核心功能模块的入口选择页面

**操作**：
- 点击"视频生成" → 进入视频生成页面
- 点击"人机对话" → 进入对话页面
- 点击"训练模型" → 进入训练页面
- 点击"打开后端显示屏" → 查看后端日志

**访问**：`http://localhost:7860/index.html`

### 🎬 视频生成页面 (`generate.html`)

**布局**：
- **左侧**：输入区域、配置选项、状态日志、历史记录
- **右侧**：视频播放区域、视频信息、诊断信息

**功能**：
- 文本输入和角色/模型选择
- 实时进度显示
- 视频播放和控制
- 历史记录管理（下拉菜单选择）
- 历史记录详情页（只读，新标签页打开）

**访问**：从主页点击"视频生成"进入

### 💬 人机对话页面 (`chat.html`)

**布局**：
- **左侧**：对话列表（侧边栏）
- **中间**：消息显示区域
- **底部**：输入框和控制按钮

**功能**：
- 文本对话
- 语音回复（自动播放）
- 对话管理（新建、切换、导出、清空）
- 消息状态显示

**访问**：从主页点击"人机对话"进入

### 🎓 模型训练页面 (`train.html`)

**布局**：
- **左侧**：训练配置表单
- **右侧**：训练监控（日志、进度、图表）

**功能**：
- 训练配置和预设
- 实时训练监控
- 训练任务管理
- 模型管理

**访问**：从主页点击"训练模型"进入

### 🖥️ 后端显示屏 (`logs.html`)

**功能**：实时查看后端日志输出

**特性**：
- 显示最近 1000 条日志（自动删除多余的，节省内存）
- 日志级别着色（info、warning、error、debug、success）
- 自动刷新（每 2 秒）
- 过滤 HTTP 请求日志
- 清空显示功能

**访问**：`http://localhost:8000/` 或从选择页面进入

### 💾 数据库内容页面 (`database.html`)

**功能**：查看数据库中的设置和视频生成记录

**内容**：
- 系统设置
- 视频生成记录
- 任务状态

**访问**：从后端显示屏点击"数据库内容"进入

---

## 常见问题

### Q1: 页面无法加载或显示空白？

**解决方案**：
1. 确保后端服务器已启动（`http://localhost:8000`）
2. 检查浏览器控制台是否有错误信息
3. 确认前端服务器正常运行（`http://localhost:7860`）
4. 检查 CORS 配置是否正确

### Q2: 视频生成失败？

**可能原因**：
- 后端服务未启动
- 模型文件不存在
- 角色音频提示文件缺失
- 服务器资源不足
- 视频转码失败

**解决方案**：
1. 查看状态日志中的具体错误信息
2. 确认后端服务正常运行
3. 检查模型文件路径是否正确
4. 确认服务器有足够的 GPU/内存资源
5. 检查 FFmpeg 是否正确安装

### Q3: 视频只有音频没有画面？

**可能原因**：
- NeRF 视频生成失败（只生成了音频）
- 视频转码失败

**解决方案**：
1. 查看后端日志中的转码相关信息
2. 检查 FFmpeg 是否正确安装
3. 确认原始视频文件是否有视频轨道
4. 查看转码错误信息

### Q4: 对话功能无响应？

**可能原因**：
- LLM API Key 未配置
- TTS 模型未加载
- 网络连接问题

**解决方案**：
1. 检查后端日志确认 LLM 和 TTS 模块是否正常
2. 确认 API Key 已正确配置
3. 查看浏览器控制台的网络请求状态

### Q5: 训练任务无法启动？

**可能原因**：
- 训练数据路径不存在
- 基础模型文件不存在
- 训练脚本路径错误

**解决方案**：
1. 确认训练数据路径正确且可访问
2. 确认基础模型文件存在于 `pretrained_networks` 目录
3. 检查后端日志查看详细错误信息

### Q6: 如何修改 API 地址？

**解决方案**：
前端会自动检测 API 地址：
- 如果前端运行在端口 7860，会自动使用后端端口 8000
- 如果挂载在 FastAPI 下，会使用当前 origin

如需手动修改，在每个 HTML 文件中找到 `FASTAPI_URL` 变量并修改。

---

## 技术架构

### 文件结构

```
fastapi_server/
├── start.py              # 一键启动脚本
├── simple_web.py         # 前端 HTTP 服务器
├── main.py               # FastAPI 后端服务器
├── utils/                # 工具模块
│   ├── run_llm_talk.py   # LLM 和 TTS 调用
│   ├── run_nerffacespeech.py  # NeRF 视频生成
│   ├── run_chat.py       # 聊天对话
│   └── run_training.py   # 训练任务管理
├── database/             # 数据库模块
│   ├── settings_db.py    # 设置数据库
│   └── video_tasks_db.py # 视频任务数据库
└── webui/                # 前端页面
    ├── start.html        # 选择页面
    ├── index.html        # 前端主页
    ├── generate.html     # 视频生成页面
    ├── chat.html         # 人机对话页面
    ├── train.html        # 模型训练页面
    ├── logs.html         # 后端显示屏
    ├── database.html     # 数据库内容页面
    ├── settings.js       # 设置管理脚本
    └── README.md         # 本文档
```

### 后端 API 接口

| 接口 | 方法 | 功能 |
|------|------|------|
| `/` | GET | 后端显示屏（logs.html） |
| `/models` | GET | 获取模型列表 |
| `/generate_video` | POST | 生成视频（异步任务） |
| `/task_status/{task_id}` | GET | 获取任务状态 |
| `/chat` | POST | 完整对话（LLM + TTS） |
| `/llm_only` | POST | 纯 LLM 问答 |
| `/train/start` | POST | 启动训练 |
| `/train/status/{task_id}` | GET | 获取训练状态 |
| `/train/tasks` | GET | 列出所有训练任务 |
| `/train/stop/{task_id}` | POST | 停止训练 |
| `/logs` | GET | 获取日志输出（限制数量） |
| `/logs/full` | GET | 获取完整日志输出（最多 1000 条） |
| `/settings` | GET/POST | 获取/更新设置 |
| `/history` | GET | 获取视频生成历史记录 |

### 数据存储

- **主题和字体设置**：保存在浏览器 `localStorage`
- **对话历史**：保存在浏览器 `localStorage`
- **训练配置预设**：保存在浏览器 `localStorage`
- **系统设置**：保存在 SQLite 数据库
- **视频生成记录**：保存在 SQLite 数据库
- **日志缓冲**：保存在后端服务器内存中（最多 1000 条，自动删除多余的）

### 视频处理流程

1. **文本输入** → LLM 生成回复
2. **TTS 合成** → 生成音频文件
3. **NeRF 生成** → 生成原始视频文件
4. **视频转码** → 使用 FFmpeg 转码为 H.264/AAC 格式（浏览器兼容）
5. **文件存储** → 保存到服务器并记录到数据库
6. **前端加载** → 从文件路径构造 URL 并播放

### 环境要求

- Python 3.10+
- FastAPI
- FFmpeg（用于视频转码）
- Conda 环境（推荐）

### 浏览器兼容性

- ✅ Chrome/Edge（推荐）
- ✅ Firefox
- ✅ Safari
- ⚠️ IE（不支持）

---

## 更新日志

### v2.1.0 (当前版本)
- ✅ 优化日志缓冲区：最多显示 1000 行，自动删除多余的，节省内存
- ✅ 改进视频转码：转码前检查视频轨道，转码后验证结果
- ✅ 修复前端加载问题：优化数据库初始化和设置加载
- ✅ 改进错误处理：转码失败时不再使用原始文件

### v2.0.0
- ✅ 一键启动脚本
- ✅ 选择页面和后端显示屏
- ✅ 训练页面全面优化
- ✅ 视频生成页面优化
- ✅ 所有页面统一设置功能

### v1.0.0
- ✅ 基础的三个功能模块
- ✅ 主题和字体自定义
- ✅ 对话管理和历史记录

---

## 联系与支持

- **团队**：北京理工大学 · NeRFFaceSpeech 团队
- **项目地址**：TFG_TALK_NeRFaceSpeech

---

**祝使用愉快！** 🎉
