"""
è§’è‰²è®­ç»ƒå·¥å…·æ¨¡å—
æ”¯æŒä»Žè§†é¢‘ä¸­æå–è®­ç»ƒæ•°æ®ï¼ˆå›¾åƒå’ŒéŸ³é¢‘ï¼‰
"""
import subprocess
import cv2
import os
import logging
from pathlib import Path
from typing import Dict, Optional, Tuple
import shutil
import tempfile

# å¯¼å…¥é…ç½®
import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from shared.config import PROJECT_ROOT, NERF_CONDA_PYTHON, MODEL_DIR, NERF_CODE_DIR, NERF_CONDA_ENV

# æ—¥å¿—å‡½æ•°ï¼ˆä¸Ž run_nerffacespeech.py ä¿æŒä¸€è‡´ï¼‰
def add_log(message, level="info"):
    """æ·»åŠ æ—¥å¿—åˆ°æ—¥å¿—ç³»ç»Ÿ"""
    logger = logging.getLogger()
    level_map = {
        "info": logging.INFO,
        "warning": logging.WARNING,
        "error": logging.ERROR,
        "success": logging.INFO,
        "progress": logging.INFO,
    }
    log_level = level_map.get(level, logging.INFO)
    logger.log(log_level, message)

# è§’è‰²æ•°æ®ç›®å½•
CHARACTER_DIR = PROJECT_ROOT / "assets" / "charactor"


def process_video_for_training(
    video_path: Path,
    character_name: str,
    face_ratio: float = 0.6,
    output_size: Tuple[int, int] = (1024, 1024),
    ffhq_alignment: bool = True,
    overwrite: bool = False,
) -> Dict:
    """
    å¤„ç†è§†é¢‘ç”¨äºŽè§’è‰²è®­ç»ƒï¼š
    1. ä½¿ç”¨ video_face_crop.py å¤„ç†è§†é¢‘ï¼ˆäººè„¸æ£€æµ‹ã€å¯¹é½ã€è£å‰ªï¼‰
    2. ä»Žå¤„ç†åŽçš„è§†é¢‘ä¸­æå–å¸§ï¼ˆä¿å­˜ä¸ºå›¾åƒï¼‰
    3. ä»ŽåŽŸå§‹è§†é¢‘ä¸­æå–éŸ³é¢‘
    
    Args:
        video_path: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
        character_name: è§’è‰²åç§°ï¼ˆç”¨äºŽåˆ›å»ºè¾“å‡ºç›®å½•ï¼‰
        face_ratio: äººè„¸å ç”»é¢çš„æ¯”ä¾‹ï¼ˆé»˜è®¤0.6ï¼‰
        output_size: è¾“å‡ºè§†é¢‘å°ºå¯¸ï¼ˆé»˜è®¤1024x1024ï¼‰
        ffhq_alignment: æ˜¯å¦ä½¿ç”¨ FFHQ å¯¹é½ï¼ˆé»˜è®¤Trueï¼‰
        overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶
    
    Returns:
        dict: å¤„ç†ç»“æžœï¼ŒåŒ…å«çŠ¶æ€ã€è¾“å‡ºè·¯å¾„ç­‰ä¿¡æ¯
    """
    import traceback
    try:
        add_log(f"[å¤„ç†] ========== å¼€å§‹å¤„ç†è§†é¢‘ç”¨äºŽè®­ç»ƒ ==========", "info")
        add_log(f"[å¤„ç†] è¾“å…¥è§†é¢‘: {video_path}", "info")
        add_log(f"[å¤„ç†] è§’è‰²åç§°: {character_name}", "info")
        add_log(f"[å¤„ç†] å‚æ•°: face_ratio={face_ratio}, output_size={output_size}, ffhq_alignment={ffhq_alignment}, overwrite={overwrite}", "info")
        
        # åˆ›å»ºè§’è‰²ç›®å½•
        character_output_dir = CHARACTER_DIR / character_name
        add_log(f"[å¤„ç†] åˆ›å»ºè§’è‰²è¾“å‡ºç›®å½•: {character_output_dir}", "info")
        character_output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ä¸”ä¸è¦†ç›–
        if not overwrite and character_output_dir.exists():
            images_dir = character_output_dir / "images"
            audio_file = character_output_dir / "audio.wav"
            if images_dir.exists() and audio_file.exists():
                add_log(f"[å¤„ç†] âš ï¸ è§’è‰²æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†", "warning")
                return {
                    "success": True,
                    "message": f"è§’è‰² {character_name} çš„è®­ç»ƒæ•°æ®å·²å­˜åœ¨",
                    "character_dir": str(character_output_dir),
                    "images_dir": str(images_dir),
                    "audio_file": str(audio_file),
                }
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºŽå¤„ç†
        temp_dir = Path(tempfile.mkdtemp(prefix="character_training_"))
        temp_video = temp_dir / "input_video.mp4"
        cropped_video = temp_dir / "cropped_video.mp4"
        add_log(f"[å¤„ç†] åˆ›å»ºä¸´æ—¶ç›®å½•: {temp_dir}", "info")
        
        # å¤åˆ¶è§†é¢‘åˆ°ä¸´æ—¶ç›®å½•
        add_log(f"[å¤„ç†] å¤åˆ¶è§†é¢‘åˆ°ä¸´æ—¶ç›®å½•...", "info")
        shutil.copy2(video_path, temp_video)
        add_log(f"[å¤„ç†] è§†é¢‘å·²å¤åˆ¶: {temp_video}", "info")
        
        # æ­¥éª¤1: ä½¿ç”¨ video_face_crop.py å¤„ç†è§†é¢‘
        add_log(f"[å¤„ç†] ========== æ­¥éª¤1: è§†é¢‘äººè„¸å¤„ç† ==========", "info")
        add_log(f"[å¤„ç†] å¼€å§‹å¤„ç†è§†é¢‘: {video_path.name}", "info")
        crop_result = crop_video_face(
            input_video=temp_video,
            output_video=cropped_video,
            face_ratio=face_ratio,
            output_size=output_size,
            ffhq_alignment=ffhq_alignment,
        )
        
        if not crop_result["success"]:
            error_msg = crop_result.get('error', 'æœªçŸ¥é”™è¯¯')
            add_log(f"[å¤„ç†] âŒ è§†é¢‘å¤„ç†å¤±è´¥: {error_msg}", "error")
            shutil.rmtree(temp_dir, ignore_errors=True)
            return {
                "success": False,
                "error": f"è§†é¢‘å¤„ç†å¤±è´¥: {error_msg}"
            }
        add_log(f"[å¤„ç†] âœ… è§†é¢‘å¤„ç†æˆåŠŸ", "info")
        
        # æ­¥éª¤2: ä»Žå¤„ç†åŽçš„è§†é¢‘ä¸­æå–å¸§
        add_log(f"[å¤„ç†] ========== æ­¥éª¤2: æå–è§†é¢‘å¸§ ==========", "info")
        images_dir = character_output_dir / "images"
        images_dir.mkdir(parents=True, exist_ok=True)
        add_log(f"[æå–] è¾“å‡ºç›®å½•: {images_dir}", "info")
        
        add_log(f"[æå–] å¼€å§‹æå–è§†é¢‘å¸§...", "info")
        extract_result = extract_frames_from_video(
            video_path=cropped_video,
            output_dir=images_dir,
            frame_prefix="frame",
        )
        
        if not extract_result["success"]:
            error_msg = extract_result.get('error', 'æœªçŸ¥é”™è¯¯')
            add_log(f"[æå–] âŒ å¸§æå–å¤±è´¥: {error_msg}", "error")
            shutil.rmtree(temp_dir, ignore_errors=True)
            return {
                "success": False,
                "error": f"å¸§æå–å¤±è´¥: {error_msg}"
            }
        num_frames = extract_result.get("num_frames", 0)
        add_log(f"[æå–] âœ… å¸§æå–æˆåŠŸï¼Œå…± {num_frames} å¸§", "info")
        
        # æ­¥éª¤3: ä»ŽåŽŸå§‹è§†é¢‘ä¸­æå–éŸ³é¢‘
        add_log(f"[å¤„ç†] ========== æ­¥éª¤3: æå–éŸ³é¢‘ ==========", "info")
        audio_file = character_output_dir / "audio.wav"
        add_log(f"[æå–] éŸ³é¢‘è¾“å‡ºæ–‡ä»¶: {audio_file}", "info")
        add_log(f"[æå–] å¼€å§‹æå–éŸ³é¢‘...", "info")
        audio_result = extract_audio_from_video(
            video_path=video_path,
            output_audio=audio_file,
        )
        
        if not audio_result["success"]:
            error_msg = audio_result.get('error', 'æœªçŸ¥é”™è¯¯')
            add_log(f"[æå–] âŒ éŸ³é¢‘æå–å¤±è´¥: {error_msg}", "error")
            shutil.rmtree(temp_dir, ignore_errors=True)
            return {
                "success": False,
                "error": f"éŸ³é¢‘æå–å¤±è´¥: {error_msg}"
            }
        add_log(f"[æå–] âœ… éŸ³é¢‘æå–æˆåŠŸ", "info")
        
        # æ­¥éª¤4: è°ƒç”¨ PTI è®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡åž‹æ–‡ä»¶
        add_log(f"[å¤„ç†] ========== æ­¥éª¤4: ç”Ÿæˆ PTI æ¨¡åž‹ ==========", "info")
        add_log(f"[è®­ç»ƒ] å¼€å§‹ç”Ÿæˆ PTI æ¨¡åž‹æ–‡ä»¶...", "info")
        pti_result = generate_pti_models(
            character_dir=character_output_dir,
            images_dir=images_dir,
            audio_file=audio_file,
            base_model="ffhq_1024.pkl",
        )
        
        if not pti_result["success"]:
            # PTI è®­ç»ƒå¤±è´¥ä¸å½±å“æ•°æ®æå–ï¼Œåªè®°å½•è­¦å‘Š
            error_msg = pti_result.get('error', 'æœªçŸ¥é”™è¯¯')
            add_log(f"[è®­ç»ƒ] âš ï¸ PTI æ¨¡åž‹ç”Ÿæˆå¤±è´¥: {error_msg}", "warning")
            add_log(f"[è®­ç»ƒ] âš ï¸ è®­ç»ƒæ•°æ®å·²æå–ï¼Œä½†æ¨¡åž‹æ–‡ä»¶æœªç”Ÿæˆï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨è¿è¡Œè®­ç»ƒ", "warning")
        else:
            add_log(f"[è®­ç»ƒ] âœ… PTI æ¨¡åž‹ç”ŸæˆæˆåŠŸ", "info")
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        add_log(f"[å¤„ç†] æ¸…ç†ä¸´æ—¶ç›®å½•...", "info")
        shutil.rmtree(temp_dir, ignore_errors=True)
        add_log(f"[å¤„ç†] ä¸´æ—¶ç›®å½•å·²æ¸…ç†", "info")
        
        result = {
            "success": True,
            "message": f"è§’è‰² {character_name} çš„è®­ç»ƒæ•°æ®å·²å‡†å¤‡å®Œæˆ",
            "character_dir": str(character_output_dir),
            "images_dir": str(images_dir),
            "audio_file": str(audio_file),
            "num_frames": num_frames,
        }
        
        # æ·»åŠ æ¨¡åž‹æ–‡ä»¶ä¿¡æ¯
        if pti_result.get("success"):
            result["pti_models"] = {
                "G_PTI": pti_result.get("G_PTI"),
                "w_PTI": pti_result.get("w_PTI"),
                "bg_PTI": pti_result.get("bg_PTI"),
            }
        
        add_log(f"[å¤„ç†] ========== å¤„ç†å®Œæˆ ==========", "info")
        return result
        
    except Exception as e:
        error_traceback = traceback.format_exc()
        add_log(f"[å¤„ç†] ========== å¤„ç†å¼‚å¸¸ ==========", "error")
        add_log(f"[å¤„ç†] âŒ å¼‚å¸¸ç±»åž‹: {type(e).__name__}", "error")
        add_log(f"[å¤„ç†] âŒ å¼‚å¸¸æ¶ˆæ¯: {str(e)}", "error")
        add_log(f"[å¤„ç†] âŒ å¼‚å¸¸å †æ ˆ:\n{error_traceback}", "error")
        add_log(f"[å¤„ç†] ========================================", "error")
        return {
            "success": False,
            "error": f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
        }


def crop_video_face(
    input_video: Path,
    output_video: Path,
    face_ratio: float = 0.6,
    output_size: Tuple[int, int] = (1024, 1024),
    ffhq_alignment: bool = True,
) -> Dict:
    """
    ä½¿ç”¨ video_face_crop.py å¤„ç†è§†é¢‘ï¼ˆäººè„¸æ£€æµ‹ã€å¯¹é½ã€è£å‰ªï¼‰
    
    Args:
        input_video: è¾“å…¥è§†é¢‘è·¯å¾„
        output_video: è¾“å‡ºè§†é¢‘è·¯å¾„
        face_ratio: äººè„¸å ç”»é¢çš„æ¯”ä¾‹
        output_size: è¾“å‡ºè§†é¢‘å°ºå¯¸
        ffhq_alignment: æ˜¯å¦ä½¿ç”¨ FFHQ å¯¹é½
    
    Returns:
        dict: å¤„ç†ç»“æžœ
    """
    try:
        # video_face_crop.py è„šæœ¬è·¯å¾„
        crop_script = PROJECT_ROOT / "eval_pipline" / "video_face_crop.py"
        
        if not crop_script.exists():
            return {
                "success": False,
                "error": f"æœªæ‰¾åˆ°è§†é¢‘å¤„ç†è„šæœ¬: {crop_script}"
            }
        
        # åˆ›å»ºä¸´æ—¶è¾“å…¥å’Œè¾“å‡ºç›®å½•ï¼ˆvideo_face_crop.py éœ€è¦ç›®å½•ï¼‰
        temp_input_dir = input_video.parent / "temp_input"
        temp_output_dir = input_video.parent / "temp_output"
        temp_input_dir.mkdir(exist_ok=True)
        temp_output_dir.mkdir(exist_ok=True)
        
        # å¤åˆ¶è§†é¢‘åˆ°ä¸´æ—¶è¾“å…¥ç›®å½•
        temp_input_video = temp_input_dir / input_video.name
        shutil.copy2(input_video, temp_input_video)
        
        # æž„å»ºå‘½ä»¤ï¼ˆä½¿ç”¨ NERF_CONDA_PYTHON ä»¥ç¡®ä¿æœ‰æ­£ç¡®çš„ä¾èµ–ï¼‰
        python_cmd = str(NERF_CONDA_PYTHON) if NERF_CONDA_PYTHON.exists() else "python"
        
        cmd = [
            python_cmd,
            str(crop_script),
            "--input-dir", str(temp_input_dir),
            "--output-dir", str(temp_output_dir),
            "--face-ratio", str(face_ratio),
            "--output-size", str(output_size[0]), str(output_size[1]),
            "--overwrite",
        ]
        
        if ffhq_alignment:
            cmd.append("--ffhq-alignment")
        
        # æ‰§è¡Œå‘½ä»¤
        add_log(f"[è§†é¢‘å¤„ç†] æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}", "info")
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            cwd=str(PROJECT_ROOT),
        )
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        output_file = temp_output_dir / temp_input_video.name
        
        # æ£€æŸ¥è„šæœ¬è¿”å›žç å’Œé”™è¯¯è¾“å‡º
        has_error = False
        error_keywords = ['é”™è¯¯', 'Error', 'ERROR', 'Exception', 'RuntimeError', 'FFHQFaceAlignment', 'æœªæ£€æµ‹åˆ°å…³é”®ç‚¹', 'å¤„ç†è§†é¢‘', 'æ—¶å‡ºé”™', 'Traceback']
        
        # æ£€æŸ¥è¿”å›žç 
        if result.returncode != 0:
            has_error = True
            add_log(f"[è§†é¢‘å¤„ç†] âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼ˆè¿”å›žç : {result.returncode}ï¼‰", "error")
        
        # æ£€æŸ¥ stderr ä¸­æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯ï¼ˆå³ä½¿è¿”å›žç ä¸º0ï¼Œä¹Ÿå¯èƒ½æœ‰é”™è¯¯ï¼‰
        error_msg = result.stderr if result.stderr else ""
        stdout_msg = result.stdout if result.stdout else ""
        
        # æ£€æŸ¥ stderr æˆ– stdout ä¸­æ˜¯å¦åŒ…å«é”™è¯¯å…³é”®è¯
        if error_msg or stdout_msg:
            combined_output = (error_msg + "\n" + stdout_msg).lower()
            if any(keyword.lower() in combined_output for keyword in error_keywords):
                has_error = True
                add_log(f"[è§†é¢‘å¤„ç†] âŒ æ£€æµ‹åˆ°é”™è¯¯ä¿¡æ¯", "error")
        
        # å¦‚æžœæ£€æµ‹åˆ°é”™è¯¯ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
        if has_error:
            add_log(f"[è§†é¢‘å¤„ç†] ========== æ£€æµ‹åˆ°é”™è¯¯ä¿¡æ¯ ==========", "error")
            add_log(f"[è§†é¢‘å¤„ç†] è¿”å›žç : {result.returncode}", "error")
            
            if error_msg:
                add_log(f"[è§†é¢‘å¤„ç†] stderr è¾“å‡º:", "error")
                # æå–å…³é”®é”™è¯¯ä¿¡æ¯
                error_lines = error_msg.split('\n')
                for line in error_lines:
                    if line.strip():  # åªè®°å½•éžç©ºè¡Œ
                        if any(keyword in line for keyword in error_keywords):
                            add_log(f"[è§†é¢‘å¤„ç†]   ERROR: {line}", "error")
                        else:
                            add_log(f"[è§†é¢‘å¤„ç†]   {line}", "info")
            
            if stdout_msg:
                add_log(f"[è§†é¢‘å¤„ç†] stdout è¾“å‡º:", "info")
                # æ£€æŸ¥ stdout ä¸­æ˜¯å¦ä¹Ÿæœ‰é”™è¯¯ä¿¡æ¯
                stdout_lines = stdout_msg.split('\n')
                for line in stdout_lines:
                    if line.strip():  # åªè®°å½•éžç©ºè¡Œ
                        if any(keyword in line for keyword in error_keywords):
                            add_log(f"[è§†é¢‘å¤„ç†]   ERROR: {line}", "error")
                        else:
                            add_log(f"[è§†é¢‘å¤„ç†]   {line}", "info")
            
            # å¦‚æžœé”™è¯¯ä¿¡æ¯å¤ªé•¿ï¼Œåªæ˜¾ç¤ºæœ€åŽéƒ¨åˆ†
            full_error = (error_msg + "\n" + stdout_msg).strip()
            error_summary = full_error[-2000:] if len(full_error) > 2000 else full_error
            
            # å¦‚æžœè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æŽ¥è¿”å›žé”™è¯¯
            if not output_file.exists():
                add_log(f"[è§†é¢‘å¤„ç†] âŒ è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {output_file}", "error")
                add_log(f"[è§†é¢‘å¤„ç†] ========================================", "error")
                # æ¸…ç†ä¸´æ—¶ç›®å½•
                shutil.rmtree(temp_input_dir, ignore_errors=True)
                shutil.rmtree(temp_output_dir, ignore_errors=True)
                
                return {
                    "success": False,
                    "error": f"è§†é¢‘å¤„ç†å¤±è´¥ï¼ˆè¿”å›žç : {result.returncode}ï¼‰ã€‚é”™è¯¯ä¿¡æ¯: {error_summary}"
                }
            # å¦‚æžœè¾“å‡ºæ–‡ä»¶å­˜åœ¨ä½†æ£€æµ‹åˆ°é”™è¯¯ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­
            else:
                add_log(f"[è§†é¢‘å¤„ç†] âš ï¸  æ£€æµ‹åˆ°é”™è¯¯ä½†è¾“å‡ºæ–‡ä»¶å·²ç”Ÿæˆï¼Œç»§ç»­å¤„ç†", "warning")
                add_log(f"[è§†é¢‘å¤„ç†] è¾“å‡ºæ–‡ä»¶: {output_file}", "info")
                add_log(f"[è§†é¢‘å¤„ç†] ========================================", "warning")
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if output_file.exists():
            # ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
            shutil.move(str(output_file), str(output_video))
            add_log(f"[è§†é¢‘å¤„ç†] âœ… è§†é¢‘å¤„ç†æˆåŠŸ: {output_video.name}", "success")
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            shutil.rmtree(temp_input_dir, ignore_errors=True)
            shutil.rmtree(temp_output_dir, ignore_errors=True)
            
            return {
                "success": True,
                "output_video": str(output_video),
            }
        else:
            # è¾“å‡ºè„šæœ¬çš„æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡ºç”¨äºŽè°ƒè¯•
            if result.stdout:
                add_log(f"[è§†é¢‘å¤„ç†] è„šæœ¬æ ‡å‡†è¾“å‡º: {result.stdout[-500:]}", "warning")
            if result.stderr:
                add_log(f"[è§†é¢‘å¤„ç†] è„šæœ¬é”™è¯¯è¾“å‡º: {result.stderr[-500:]}", "error")
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            shutil.rmtree(temp_input_dir, ignore_errors=True)
            shutil.rmtree(temp_output_dir, ignore_errors=True)
            
            error_msg = result.stderr if result.stderr else result.stdout
            error_summary = error_msg[-1000:] if error_msg and len(error_msg) > 1000 else (error_msg or "æœªçŸ¥é”™è¯¯")
            
            return {
                "success": False,
                "error": f"è§†é¢‘å¤„ç†å¤±è´¥ï¼Œæœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶ã€‚é”™è¯¯ä¿¡æ¯: {error_summary}"
            }
            
    except Exception as e:
        return {
            "success": False,
            "error": f"è§†é¢‘å¤„ç†å¼‚å¸¸: {str(e)}"
        }


def extract_frames_from_video(
    video_path: Path,
    output_dir: Path,
    frame_prefix: str = "frame",
    image_format: str = "jpg",
) -> Dict:
    """
    ä»Žè§†é¢‘ä¸­æå–æ‰€æœ‰å¸§å¹¶ä¿å­˜ä¸ºå›¾åƒ
    
    Args:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_dir: è¾“å‡ºå›¾åƒç›®å½•
        frame_prefix: å¸§æ–‡ä»¶åå‰ç¼€
        image_format: å›¾åƒæ ¼å¼ï¼ˆjpg/pngï¼‰
    
    Returns:
        dict: æå–ç»“æžœï¼ŒåŒ…å«æå–çš„å¸§æ•°
    """
    try:
        output_dir.mkdir(parents=True, exist_ok=True)
        
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            return {
                "success": False,
                "error": f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}"
            }
        
        frame_count = 0
        frame_idx = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # ä¿å­˜å¸§
            frame_filename = f"{frame_prefix}_{frame_idx:06d}.{image_format}"
            frame_path = output_dir / frame_filename
            cv2.imwrite(str(frame_path), frame)
            
            frame_count += 1
            frame_idx += 1
        
        cap.release()
        
        return {
            "success": True,
            "num_frames": frame_count,
            "output_dir": str(output_dir),
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"å¸§æå–å¼‚å¸¸: {str(e)}"
        }


def extract_audio_from_video(
    video_path: Path,
    output_audio: Path,
    sample_rate: int = 16000,
    channels: int = 1,
) -> Dict:
    """
    ä»Žè§†é¢‘ä¸­æå–éŸ³é¢‘å¹¶ä¿å­˜ä¸º WAV æ–‡ä»¶
    
    Args:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_audio: è¾“å‡ºéŸ³é¢‘è·¯å¾„
        sample_rate: é‡‡æ ·çŽ‡ï¼ˆé»˜è®¤16000Hzï¼‰
        channels: å£°é“æ•°ï¼ˆé»˜è®¤1ï¼Œå•å£°é“ï¼‰
    
    Returns:
        dict: æå–ç»“æžœ
    """
    try:
        output_audio.parent.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨ ffmpeg æå–éŸ³é¢‘
        cmd = [
            "ffmpeg",
            "-y",
            "-i", str(video_path),
            "-vn",  # ä¸åŒ…å«è§†é¢‘
            "-acodec", "pcm_s16le",  # PCM 16ä½å°ç«¯
            "-ar", str(sample_rate),  # é‡‡æ ·çŽ‡
            "-ac", str(channels),  # å£°é“æ•°
            str(output_audio),
        ]
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
        )
        
        if result.returncode != 0:
            return {
                "success": False,
                "error": f"éŸ³é¢‘æå–å¤±è´¥: {result.stderr[:500]}"
            }
        
        if not output_audio.exists():
            return {
                "success": False,
                "error": "éŸ³é¢‘æ–‡ä»¶æœªç”Ÿæˆ"
            }
        
        return {
            "success": True,
            "output_audio": str(output_audio),
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"éŸ³é¢‘æå–å¼‚å¸¸: {str(e)}"
        }


def get_character_training_status(character_name: str) -> Dict:
    """
    èŽ·å–è§’è‰²è®­ç»ƒæ•°æ®çš„çŠ¶æ€
    
    Args:
        character_name: è§’è‰²åç§°
    
    Returns:
        dict: çŠ¶æ€ä¿¡æ¯
    """
    character_dir = CHARACTER_DIR / character_name
    
    if not character_dir.exists():
        return {
            "exists": False,
            "character_name": character_name,
        }
    
    images_dir = character_dir / "images"
    audio_file = character_dir / "audio.wav"
    
    num_images = 0
    if images_dir.exists():
        num_images = len(list(images_dir.glob("*.jpg"))) + len(list(images_dir.glob("*.png")))
    
    audio_exists = audio_file.exists()
    
    # æ£€æŸ¥ PTI æ¨¡åž‹æ–‡ä»¶
    g_pti = character_dir / "G_PTI.pt"
    w_pti = character_dir / "w_PTI.pt"
    bg_pti = character_dir / "bg_PTI.pt"
    
    pti_models_exist = {
        "G_PTI": g_pti.exists(),
        "w_PTI": w_pti.exists(),
        "bg_PTI": bg_pti.exists(),
    }
    all_pti_models_exist = all(pti_models_exist.values())
    
    return {
        "exists": True,
        "character_name": character_name,
        "character_dir": str(character_dir),
        "images_dir": str(images_dir) if images_dir.exists() else None,
        "num_images": num_images,
        "audio_file": str(audio_file) if audio_exists else None,
        "audio_exists": audio_exists,
        "pti_models": pti_models_exist,
        "pti_models_exist": all_pti_models_exist,
    }


def generate_pti_models(
    character_dir: Path,
    images_dir: Path,
    audio_file: Path,
    base_model: str = "ffhq_1024.pkl",
    truncation_psi: float = 1.0,
) -> Dict:
    """
    è°ƒç”¨ main_NeRFFaceSpeech_audio_driven_w_given_poses.py ç”Ÿæˆ PTI æ¨¡åž‹æ–‡ä»¶
    
    Args:
        character_dir: è§’è‰²ç›®å½•ï¼ˆè¾“å‡ºç›®å½•ï¼‰
        images_dir: å›¾åƒç›®å½•ï¼ˆç”¨äºŽ motion_guide_img_folderï¼‰
        audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        base_model: åŸºç¡€æ¨¡åž‹æ–‡ä»¶åï¼ˆé»˜è®¤ ffhq_1024.pklï¼‰
        truncation_psi: Truncation psi å‚æ•°ï¼ˆé»˜è®¤ 1.0ï¼‰
    
    Returns:
        dict: å¤„ç†ç»“æžœï¼ŒåŒ…å«ç”Ÿæˆçš„æ¨¡åž‹æ–‡ä»¶è·¯å¾„
    """
    try:
        # æ£€æŸ¥åŸºç¡€æ¨¡åž‹æ˜¯å¦å­˜åœ¨
        base_model_path = MODEL_DIR / base_model
        if not base_model_path.exists():
            return {
                "success": False,
                "error": f"åŸºç¡€æ¨¡åž‹ä¸å­˜åœ¨: {base_model_path}"
            }
        
        # æ£€æŸ¥å›¾åƒç›®å½•æ˜¯å¦å­˜åœ¨ä¸”æœ‰å›¾åƒæ–‡ä»¶
        if not images_dir.exists():
            return {
                "success": False,
                "error": f"å›¾åƒç›®å½•ä¸å­˜åœ¨: {images_dir}"
            }
        
        image_files = list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.png"))
        if not image_files:
            return {
                "success": False,
                "error": f"å›¾åƒç›®å½•ä¸­æ²¡æœ‰å›¾åƒæ–‡ä»¶: {images_dir}"
            }
        
        # é€‰æ‹©ç¬¬ä¸€å¸§ä½œä¸ºè¾“å…¥å›¾åƒï¼ˆç”¨äºŽ PTIï¼‰
        test_img = sorted(image_files)[0]
        
        # éªŒè¯è¾“å…¥å›¾åƒæ–‡ä»¶
        if not test_img.exists():
            return {
                "success": False,
                "error": f"è¾“å…¥å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {test_img}"
            }
        
        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not audio_file.exists():
            return {
                "success": False,
                "error": f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}"
            }
        
        # éªŒè¯æ‰€æœ‰è·¯å¾„éƒ½æ˜¯ç»å¯¹è·¯å¾„ï¼ˆé¿å…ç›¸å¯¹è·¯å¾„é—®é¢˜ï¼‰
        test_img = test_img.resolve()
        audio_file = audio_file.resolve()
        images_dir = images_dir.resolve()
        character_dir = character_dir.resolve()
        base_model_path = base_model_path.resolve()
        
        # æ£€æŸ¥æ¨¡åž‹æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        g_pti = character_dir / "G_PTI.pt"
        w_pti = character_dir / "w_PTI.pt"
        bg_pti = character_dir / "bg_PTI.pt"
        
        if g_pti.exists() and w_pti.exists() and bg_pti.exists():
            add_log(f"[PTIè®­ç»ƒ] âœ… æ¨¡åž‹æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡è®­ç»ƒ", "info")
            return {
                "success": True,
                "G_PTI": str(g_pti),
                "w_PTI": str(w_pti),
                "bg_PTI": str(bg_pti),
                "models_generated": ["G_PTI.pt", "w_PTI.pt", "bg_PTI.pt"],
                "skipped": True,
            }
        
        # PTI è®­ç»ƒè„šæœ¬è·¯å¾„
        pti_script = NERF_CODE_DIR / "StyleNeRF" / "main_NeRFFaceSpeech_audio_driven_w_given_poses.py"
        if not pti_script.exists():
            return {
                "success": False,
                "error": f"PTI è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨: {pti_script}"
            }
        
        # å¦‚æžœè§†é¢‘æ–‡ä»¶å­˜åœ¨ï¼Œåˆ é™¤å®ƒä»¥ç¡®ä¿è„šæœ¬ä¼šé‡æ–°è¿è¡Œå¹¶ç”Ÿæˆæ¨¡åž‹æ–‡ä»¶
        output_video = character_dir / "output_NeRFFaceSpeech.mp4"
        if output_video.exists():
            add_log(f"[PTIè®­ç»ƒ] åˆ é™¤å·²å­˜åœ¨çš„è§†é¢‘æ–‡ä»¶ä»¥é‡æ–°ç”Ÿæˆæ¨¡åž‹: {output_video}", "info")
            try:
                output_video.unlink()
            except Exception as e:
                add_log(f"[PTIè®­ç»ƒ] âš ï¸  åˆ é™¤è§†é¢‘æ–‡ä»¶å¤±è´¥: {e}", "warning")
        
        # æž„å»ºå‘½ä»¤
        # è„šæœ¬è·¯å¾„ä½¿ç”¨ç›¸å¯¹äºŽå·¥ä½œç›®å½•çš„è·¯å¾„ï¼ˆå·¥ä½œç›®å½•æ˜¯ NERF_CODE_DIRï¼‰
        script_relative_path = Path("StyleNeRF") / pti_script.name
        cmd = [
            str(NERF_CONDA_PYTHON),
            str(script_relative_path),  # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œå› ä¸ºå·¥ä½œç›®å½•æ˜¯ NERF_CODE_DIR
            "--network", str(base_model_path),
            "--outdir", str(character_dir),
            "--test_data", str(audio_file),
            "--test_img", str(test_img),
            "--motion_guide_img_folder", str(images_dir),
            "--trunc", str(truncation_psi),
            "--noise-mode", "const",
        ]
        
        add_log(f"[PTIè®­ç»ƒ] æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}", "info")
        add_log(f"[PTIè®­ç»ƒ] å‚æ•°éªŒè¯:", "info")
        add_log(f"[PTIè®­ç»ƒ]   è¾“å…¥å›¾åƒ: {test_img} (å­˜åœ¨: {test_img.exists()})", "info")
        add_log(f"[PTIè®­ç»ƒ]   éŸ³é¢‘æ–‡ä»¶: {audio_file} (å­˜åœ¨: {audio_file.exists()})", "info")
        add_log(f"[PTIè®­ç»ƒ]   å›¾åƒç›®å½•: {images_dir} (å­˜åœ¨: {images_dir.exists()}, å›¾åƒæ•°: {len(image_files)})", "info")
        add_log(f"[PTIè®­ç»ƒ]   è¾“å‡ºç›®å½•: {character_dir} (å­˜åœ¨: {character_dir.exists()})", "info")
        add_log(f"[PTIè®­ç»ƒ]   åŸºç¡€æ¨¡åž‹: {base_model_path} (å­˜åœ¨: {base_model_path.exists()})", "info")
        
        # å†æ¬¡éªŒè¯å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not test_img.exists():
            return {
                "success": False,
                "error": f"è¾“å…¥å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {test_img}"
            }
        if not audio_file.exists():
            return {
                "success": False,
                "error": f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}"
            }
        if not base_model_path.exists():
            return {
                "success": False,
                "error": f"åŸºç¡€æ¨¡åž‹æ–‡ä»¶ä¸å­˜åœ¨: {base_model_path}"
            }
        
        # æ‰§è¡Œå‘½ä»¤ï¼ˆPTI è®­ç»ƒå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰
        add_log(f"[PTIè®­ç»ƒ] å¼€å§‹è®­ç»ƒï¼Œè¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...", "info")
        add_log(f"[PTIè®­ç»ƒ] ä½¿ç”¨ Python çŽ¯å¢ƒ: {NERF_CONDA_PYTHON}", "info")
        
        # è„šæœ¬ä½¿ç”¨ç›¸å¯¹è·¯å¾„ pretrained_networks/seg.pthï¼Œéœ€è¦ä»Ž NERF_CODE_DIR è¿è¡Œ
        # è€Œä¸æ˜¯ä»Ž StyleNeRF ç›®å½•è¿è¡Œ
        script_work_dir = NERF_CODE_DIR
        add_log(f"[PTIè®­ç»ƒ] å·¥ä½œç›®å½•: {script_work_dir}", "info")
        
        # è®¾ç½®çŽ¯å¢ƒå˜é‡ï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ Python è·¯å¾„å’Œæ¨¡å—è·¯å¾„
        env = os.environ.copy()
        # æ·»åŠ  StyleNeRF ç›®å½•åˆ° PYTHONPATHï¼Œä»¥ä¾¿å¯¼å…¥æ¨¡å—
        env["PYTHONPATH"] = str(NERF_CODE_DIR / "StyleNeRF") + os.pathsep + str(NERF_CODE_DIR) + os.pathsep + env.get("PYTHONPATH", "")
        # ç¡®ä¿ PATH åŒ…å« nerffacespeech çŽ¯å¢ƒçš„ bin ç›®å½•ï¼Œä»¥ä¾¿æ‰¾åˆ° ninja ç­‰å·¥å…·
        nerf_env_bin = NERF_CONDA_ENV / "bin"
        if nerf_env_bin.exists():
            current_path = env.get("PATH", "")
            env["PATH"] = str(nerf_env_bin) + os.pathsep + current_path
            add_log(f"[PTIè®­ç»ƒ] è®¾ç½® PATHï¼ŒåŒ…å«: {nerf_env_bin}", "info")
        
        # ä½¿ç”¨ Popen å®žæ—¶è¾“å‡ºæ—¥å¿—ï¼ˆä¸ŽæŽ¨ç†æ—¶ä¿æŒä¸€è‡´ï¼‰
        add_log(f"[PTIè®­ç»ƒ] æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}", "info")
        
        try:
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                encoding='utf-8',
                errors='replace',  # ä½¿ç”¨replaceæ¨¡å¼å¤„ç†éžUTF-8å­—èŠ‚ï¼Œé¿å…è§£ç é”™è¯¯
                bufsize=1,
                env=env,
                cwd=str(script_work_dir),
                universal_newlines=True
            )
            
            # å®žæ—¶è¯»å–è¾“å‡ºå¹¶æ·»åŠ åˆ°æ—¥å¿—
            error_lines = []  # æ”¶é›†é”™è¯¯ä¿¡æ¯
            for line in process.stdout:
                if line:
                    line = line.rstrip()
                    # æ ¹æ®å†…å®¹åˆ¤æ–­æ—¥å¿—çº§åˆ«
                    if 'ERROR' in line or 'é”™è¯¯' in line or 'Error' in line or 'Exception' in line or 'Traceback' in line or 'FileNotFoundError' in line or 'RuntimeError' in line:
                        add_log(f"[PTIè®­ç»ƒ] {line}", "error")
                        error_lines.append(line)
                    elif 'WARNING' in line or 'è­¦å‘Š' in line or 'Warning' in line or 'WARN' in line:
                        add_log(f"[PTIè®­ç»ƒ] {line}", "warning")
                    elif '%|' in line or 'it/s' in line or 'Processing frames' in line or 'tqdm' in line.lower():
                        # è®­ç»ƒè¿›åº¦ä¿¡æ¯
                        add_log(f"[PTIè®­ç»ƒ] {line}", "progress")
                    elif 'Loading' in line or 'loading' in line or 'Loaded' in line:
                        add_log(f"[PTIè®­ç»ƒ] {line}", "info")
                    elif 'epoch' in line.lower() or 'iteration' in line.lower() or 'step' in line.lower():
                        add_log(f"[PTIè®­ç»ƒ] {line}", "progress")
                    elif line.strip():  # å¿½ç•¥ç©ºè¡Œ
                        add_log(f"[PTIè®­ç»ƒ] {line}", "info")
            
            process.wait()
            result_code = process.returncode
            
            # ä¸ºäº†å…¼å®¹åŽç»­ä»£ç ï¼Œåˆ›å»ºä¸€ä¸ªç±»ä¼¼ subprocess.run çš„ç»“æžœå¯¹è±¡
            # å°†é”™è¯¯ä¿¡æ¯åˆå¹¶ä¸ºå­—ç¬¦ä¸²
            error_output = "\n".join(error_lines) if error_lines else ""
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç»“æžœå¯¹è±¡
            class ProcessResult:
                def __init__(self, returncode, stderr="", stdout=""):
                    self.returncode = returncode
                    self.stderr = stderr
                    self.stdout = stdout
            
            result = ProcessResult(result_code, stderr=error_output, stdout="")
            
        except Exception as e:
            add_log(f"[PTIè®­ç»ƒ] æ‰§è¡Œè¿‡ç¨‹å¼‚å¸¸: {str(e)}", "error")
            # åˆ›å»ºå¤±è´¥ç»“æžœ
            class ProcessResult:
                def __init__(self, returncode, stderr="", stdout=""):
                    self.returncode = returncode
                    self.stderr = stderr
                    self.stdout = stdout
            result = ProcessResult(1, stderr=str(e), stdout="")
        
        # æ£€æŸ¥ç”Ÿæˆçš„æ¨¡åž‹æ–‡ä»¶
        models_generated = []
        if g_pti.exists():
            models_generated.append("G_PTI.pt")
        if w_pti.exists():
            models_generated.append("w_PTI.pt")
        if bg_pti.exists():
            models_generated.append("bg_PTI.pt")
        
        # å¦‚æžœæ¨¡åž‹æ–‡ä»¶å·²ç”Ÿæˆï¼Œå³ä½¿è¿”å›žç ä¸ä¸º0ä¹Ÿè®¤ä¸ºæˆåŠŸï¼ˆè„šæœ¬å¯èƒ½åœ¨å…¶ä»–åœ°æ–¹å‡ºé”™ä½†æ¨¡åž‹å·²ç”Ÿæˆï¼‰
        if len(models_generated) >= 2:
            add_log(f"[PTIè®­ç»ƒ] âœ… æ¨¡åž‹æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {', '.join(models_generated)}", "success")
            if result.returncode != 0:
                add_log(f"[PTIè®­ç»ƒ] âš ï¸  è„šæœ¬è¿”å›žç : {result.returncode}ï¼Œä½†æ¨¡åž‹æ–‡ä»¶å·²ç”Ÿæˆ", "warning")
            return {
                "success": True,
                "G_PTI": str(g_pti) if g_pti.exists() else None,
                "w_PTI": str(w_pti) if w_pti.exists() else None,
                "bg_PTI": str(bg_pti) if bg_pti.exists() else None,
                "models_generated": models_generated,
            }
        else:
            # å¦‚æžœæ¨¡åž‹æ–‡ä»¶æœªç”Ÿæˆï¼Œè¾“å‡ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
            error_msg = ""
            if result.stderr:
                error_msg = result.stderr
            elif result.stdout:
                error_msg = result.stdout
            else:
                error_msg = "æœªçŸ¥é”™è¯¯"
            
            add_log(f"[PTIè®­ç»ƒ] âŒ è®­ç»ƒå¤±è´¥ï¼ˆè¿”å›žç : {result.returncode}ï¼‰", "error")
            
            # æ£€æŸ¥å¸¸è§é”™è¯¯å¹¶æä¾›è§£å†³å»ºè®®
            error_lower = error_msg.lower()
            suggestions = []
            
            if "ninja is required" in error_lower or "ninja" in error_lower:
                suggestions.append("ç¼ºå°‘ Ninja æž„å»ºå·¥å…·ã€‚è¯·å®‰è£…: apt-get install ninja-build æˆ– conda install ninja")
            if "cuda" in error_lower and ("not found" in error_lower or "unavailable" in error_lower):
                suggestions.append("CUDA ä¸å¯ç”¨ã€‚è¯·æ£€æŸ¥ GPU å’Œ CUDA çŽ¯å¢ƒé…ç½®")
            if "no module named" in error_lower:
                suggestions.append("ç¼ºå°‘ Python æ¨¡å—ã€‚è¯·æ£€æŸ¥ nerffacespeech çŽ¯å¢ƒçš„ä¾èµ–æ˜¯å¦å®Œæ•´å®‰è£…")
            if "file not found" in error_lower or "no such file" in error_lower:
                suggestions.append("æ–‡ä»¶æœªæ‰¾åˆ°ã€‚è¯·æ£€æŸ¥æ‰€æœ‰å¿…éœ€çš„é¢„è®­ç»ƒæ¨¡åž‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
            
            # è¾“å‡ºé”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—ï¼ˆé”™è¯¯ä¿¡æ¯å·²ç»åœ¨å®žæ—¶è¾“å‡ºä¸­è®°å½•ï¼Œè¿™é‡Œåªè¾“å‡ºæ‘˜è¦ï¼‰
            if result.stderr:
                add_log(f"[PTIè®­ç»ƒ] é”™è¯¯æ‘˜è¦: {result.stderr[:500]}", "error")
            
            if suggestions:
                add_log(f"[PTIè®­ç»ƒ] ðŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:", "warning")
                for i, suggestion in enumerate(suggestions, 1):
                    add_log(f"[PTIè®­ç»ƒ]   {i}. {suggestion}", "warning")
            
            # æå–å…³é”®é”™è¯¯ä¿¡æ¯ï¼ˆæœ€åŽ1000å­—ç¬¦ç”¨äºŽè¿”å›žï¼‰
            error_summary = error_msg[-1000:] if len(error_msg) > 1000 else error_msg
            
            return {
                "success": False,
                "error": f"PTI è®­ç»ƒå¤±è´¥ï¼ˆè¿”å›žç : {result.returncode}ï¼‰: {error_summary}",
                "models_generated": models_generated,
                "returncode": result.returncode,
                "full_error": error_msg,  # ä¿å­˜å®Œæ•´é”™è¯¯ä¿¡æ¯
                "suggestions": suggestions,  # æä¾›è§£å†³å»ºè®®
            }
            
    except Exception as e:
        return {
            "success": False,
            "error": f"PTI è®­ç»ƒå¼‚å¸¸: {str(e)}"
        }


def list_characters() -> Dict:
    """
    åˆ—å‡ºæ‰€æœ‰å·²è®­ç»ƒçš„è§’è‰²
    
    Returns:
        dict: è§’è‰²åˆ—è¡¨
    """
    characters = []
    
    if not CHARACTER_DIR.exists():
        return {
            "success": True,
            "characters": [],
        }
    
    for char_dir in CHARACTER_DIR.iterdir():
        if char_dir.is_dir():
            status = get_character_training_status(char_dir.name)
            characters.append(status)
    
    return {
        "success": True,
        "characters": characters,
    }

