import torch
import io
import base64
import logging
import tempfile
import os
from typing import Optional, Dict, Any, Union
import soundfile as sf
import numpy as np

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
ASR_MODEL = None  # å»¶è¿ŸåŠ è½½
MODEL_NAME = "base"  # é»˜è®¤æ¨¡å‹ï¼štiny, base, small, medium, large

#---------------------------------------------------------------------

class ASRError(Exception):
    """è‡ªå®šä¹‰ASRå¼‚å¸¸ç±»"""
    def __init__(self, message: str, error_code: str = None, original_error: Exception = None):
        self.message = message
        self.error_code = error_code
        self.original_error = original_error
        super().__init__(self.message)
        
#---------------------------------------------------------------------

def load_asr_model(model_name: str = "base"):
    """
    å»¶è¿ŸåŠ è½½Whisper ASRæ¨¡å‹
    
    Args:
        model_name: Whisperæ¨¡å‹åç§° (tiny, base, small, medium, large)
    
    Returns:
        åŠ è½½çš„Whisperæ¨¡å‹
    """
    global ASR_MODEL, MODEL_NAME
    
    # å¦‚æœæ¨¡å‹å·²åŠ è½½ä¸”æ¨¡å‹åç§°ç›¸åŒï¼Œç›´æ¥è¿”å›
    if ASR_MODEL is not None and MODEL_NAME == model_name:
        return ASR_MODEL
    
    try:
        import whisper
        
        logger.info(f"æ­£åœ¨åŠ è½½Whisperæ¨¡å‹ '{model_name}' åˆ°è®¾å¤‡: {DEVICE}")
        
        # å¦‚æœå·²åŠ è½½äº†ä¸åŒæ¨¡å‹ï¼Œå…ˆé‡Šæ”¾
        if ASR_MODEL is not None:
            unload_asr_model()
        
        # åŠ è½½æ–°æ¨¡å‹
        ASR_MODEL = whisper.load_model(model_name, device=DEVICE)
        MODEL_NAME = model_name
        
        logger.info(f"Whisperæ¨¡å‹ '{model_name}' åŠ è½½æˆåŠŸ")
        return ASR_MODEL
        
    except ImportError:
        error_msg = "æœªå®‰è£…whisperåº“ï¼Œè¯·è¿è¡Œ: pip install openai-whisper"
        logger.error(error_msg)
        raise ASRError(error_msg, "WHISPER_NOT_INSTALLED")
    except Exception as e:
        error_msg = f"Whisperæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        raise ASRError(error_msg, "MODEL_LOAD_ERROR", e)

def unload_asr_model():
    """
    ä»å†…å­˜ä¸­é‡Šæ”¾ASRæ¨¡å‹
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸé‡Šæ”¾
    """
    global ASR_MODEL, MODEL_NAME
    
    try:
        if ASR_MODEL is not None:
            logger.info("æ­£åœ¨é‡Šæ”¾Whisperæ¨¡å‹...")
            
            # åˆ é™¤æ¨¡å‹å¼•ç”¨
            del ASR_MODEL
            ASR_MODEL = None
            MODEL_NAME = "base"
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()
            
            # å¦‚æœä½¿ç”¨CUDAï¼Œæ¸…ç†GPUå†…å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            
            logger.info("Whisperæ¨¡å‹å·²æˆåŠŸé‡Šæ”¾")
            return True
        else:
            logger.info("Whisperæ¨¡å‹æœªåŠ è½½ï¼Œæ— éœ€é‡Šæ”¾")
            return True
            
    except Exception as e:
        error_msg = f"Whisperæ¨¡å‹é‡Šæ”¾å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        # å³ä½¿é‡Šæ”¾å¤±è´¥ï¼Œä¹Ÿå°è¯•é‡ç½®å…¨å±€å˜é‡
        ASR_MODEL = None
        MODEL_NAME = "base"
        return False

def reload_asr_model(model_name: str = "base"):
    """
    é‡æ–°åŠ è½½ASRæ¨¡å‹ï¼ˆå…ˆé‡Šæ”¾å†åŠ è½½ï¼‰
    
    Args:
        model_name: Whisperæ¨¡å‹åç§°
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸé‡æ–°åŠ è½½
    """
    try:
        logger.info(f"å¼€å§‹é‡æ–°åŠ è½½Whisperæ¨¡å‹ '{model_name}'...")
        
        # å…ˆé‡Šæ”¾ç°æœ‰æ¨¡å‹
        unload_success = unload_asr_model()
        if not unload_success:
            logger.warning("æ¨¡å‹é‡Šæ”¾å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•é‡æ–°åŠ è½½")
        
        # é‡æ–°åŠ è½½æ¨¡å‹
        load_asr_model(model_name)
        
        logger.info(f"Whisperæ¨¡å‹ '{model_name}' é‡æ–°åŠ è½½æˆåŠŸ")
        return True
        
    except Exception as e:
        error_msg = f"Whisperæ¨¡å‹é‡æ–°åŠ è½½å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        raise ASRError(error_msg, "MODEL_RELOAD_ERROR", e)

def get_model_status():
    """
    è·å–ASRæ¨¡å‹çŠ¶æ€
    
    Returns:
        dict: æ¨¡å‹çŠ¶æ€ä¿¡æ¯
    """
    global ASR_MODEL, MODEL_NAME
    
    status = {
        'loaded': ASR_MODEL is not None,
        'model_name': MODEL_NAME,
        'device': DEVICE,
        'cuda_available': torch.cuda.is_available(),
        'memory_info': {}
    }
    
    if ASR_MODEL is not None:
        status['model_type'] = type(ASR_MODEL).__name__
        
        # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
        if torch.cuda.is_available():
            status['memory_info'] = {
                'allocated': torch.cuda.memory_allocated(),
                'reserved': torch.cuda.memory_reserved(),
                'max_allocated': torch.cuda.max_memory_allocated(),
                'max_reserved': torch.cuda.max_memory_reserved()
            }
    
    return status

#---------------------------------------------------------------------

def transcribe_audio_file(audio_path: str,
                         model_name: str = "base",
                         language: Optional[str] = None,
                         task: str = "transcribe",
                         **kwargs) -> Dict[str, Any]:
    """
    ä»éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè¯­éŸ³è¯†åˆ«
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        model_name: Whisperæ¨¡å‹åç§°
        language: è¯­è¨€ä»£ç  (å¦‚ 'zh', 'en')ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
        task: ä»»åŠ¡ç±»å‹ ('transcribe' æˆ– 'translate')
        **kwargs: å…¶ä»–Whisperå‚æ•°
    
    Returns:
        Dict[str, Any]: è¯†åˆ«ç»“æœ
        {
            'success': bool,
            'data': {
                'text': str,  # è¯†åˆ«çš„æ–‡æœ¬
                'language': str,  # æ£€æµ‹åˆ°çš„è¯­è¨€
                'segments': list,  # åˆ†æ®µä¿¡æ¯
                'info': dict  # å…¶ä»–ä¿¡æ¯
            },
            'error': None or dict
        }
    """
    try:
        # è¾“å…¥éªŒè¯
        if not audio_path or not isinstance(audio_path, str):
            raise ASRError("éŸ³é¢‘æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²", "INVALID_INPUT")
        
        if not os.path.exists(audio_path):
            raise ASRError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}", "FILE_NOT_FOUND")
        
        logger.info(f"å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼ŒéŸ³é¢‘æ–‡ä»¶: {audio_path}")
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_name}, è¯­è¨€: {language or 'è‡ªåŠ¨æ£€æµ‹'}, ä»»åŠ¡: {task}")
        
        # åŠ è½½æ¨¡å‹
        model = load_asr_model(model_name)
        
        # æ‰§è¡Œè¯†åˆ«
        result = model.transcribe(
            audio_path,
            language=language,
            task=task,
            **kwargs
        )
        
        # éªŒè¯ç»“æœ
        if not result or 'text' not in result:
            raise ASRError("Whisperè¿”å›ç©ºç»“æœ", "EMPTY_RESULT")
        
        text = result.get('text', '').strip()
        detected_language = result.get('language', 'unknown')
        segments = result.get('segments', [])
        
        logger.info(f"è¯­éŸ³è¯†åˆ«æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
        logger.info(f"æ£€æµ‹åˆ°çš„è¯­è¨€: {detected_language}")
        logger.info(f"è¯†åˆ«æ–‡æœ¬: {text[:100]}...")
        
        return {
            'success': True,
            'data': {
                'text': text,
                'language': detected_language,
                'segments': segments,
                'info': {k: v for k, v in result.items() if k not in ['text', 'language', 'segments']}
            },
            'error': None
        }
        
    except ASRError:
        # é‡æ–°æŠ›å‡ºASRé”™è¯¯
        raise
    except Exception as e:
        # æ•è·å…¶ä»–å¼‚å¸¸å¹¶è½¬æ¢ä¸ºASRé”™è¯¯
        error_msg = f"è¯­éŸ³è¯†åˆ«æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
        logger.error(error_msg)
        raise ASRError(error_msg, "TRANSCRIPTION_ERROR", e)

def transcribe_audio_data(audio_data: Union[bytes, np.ndarray],
                         sample_rate: Optional[int] = None,
                         model_name: str = "base",
                         language: Optional[str] = None,
                         task: str = "transcribe",
                         **kwargs) -> Dict[str, Any]:
    """
    ä»éŸ³é¢‘æ•°æ®è¿›è¡Œè¯­éŸ³è¯†åˆ«
    
    Args:
        audio_data: éŸ³é¢‘æ•°æ® (bytesæ ¼å¼çš„WAVæ•°æ®ï¼Œæˆ–numpyæ•°ç»„)
        sample_rate: é‡‡æ ·ç‡ï¼ˆå¦‚æœaudio_dataæ˜¯numpyæ•°ç»„ï¼‰
        model_name: Whisperæ¨¡å‹åç§°
        language: è¯­è¨€ä»£ç  (å¦‚ 'zh', 'en')ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
        task: ä»»åŠ¡ç±»å‹ ('transcribe' æˆ– 'translate')
        **kwargs: å…¶ä»–Whisperå‚æ•°
    
    Returns:
        Dict[str, Any]: è¯†åˆ«ç»“æœ
    """
    try:
        # è¾“å…¥éªŒè¯
        if audio_data is None:
            raise ASRError("éŸ³é¢‘æ•°æ®ä¸èƒ½ä¸ºç©º", "INVALID_INPUT")
        
        logger.info(f"å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼Œæ•°æ®ç±»å‹: {type(audio_data)}")
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜éŸ³é¢‘æ•°æ®
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            tmp_path = tmp_file.name
            
            try:
                # å¤„ç†ä¸åŒç±»å‹çš„éŸ³é¢‘æ•°æ®
                if isinstance(audio_data, bytes):
                    # å¦‚æœæ˜¯bytesï¼Œç›´æ¥å†™å…¥æ–‡ä»¶
                    tmp_file.write(audio_data)
                    tmp_file.flush()
                elif isinstance(audio_data, np.ndarray):
                    # å¦‚æœæ˜¯numpyæ•°ç»„ï¼Œéœ€è¦æŒ‡å®šé‡‡æ ·ç‡
                    if sample_rate is None:
                        raise ASRError("numpyæ•°ç»„æ ¼å¼éœ€è¦æä¾›sample_rateå‚æ•°", "MISSING_SAMPLE_RATE")
                    
                    # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯1Dæ•°ç»„
                    if audio_data.ndim > 1:
                        audio_data = audio_data.flatten()
                    
                    # ä¿å­˜ä¸ºWAVæ–‡ä»¶
                    sf.write(tmp_path, audio_data, sample_rate, format='WAV')
                else:
                    raise ASRError(f"ä¸æ”¯æŒçš„éŸ³é¢‘æ•°æ®ç±»å‹: {type(audio_data)}", "UNSUPPORTED_AUDIO_TYPE")
                
                # è°ƒç”¨æ–‡ä»¶è¯†åˆ«å‡½æ•°
                result = transcribe_audio_file(
                    tmp_path,
                    model_name=model_name,
                    language=language,
                    task=task,
                    **kwargs
                )
                
                return result
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    if os.path.exists(tmp_path):
                        os.unlink(tmp_path)
                except Exception as e:
                    logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")
        
    except ASRError:
        # é‡æ–°æŠ›å‡ºASRé”™è¯¯
        raise
    except Exception as e:
        # æ•è·å…¶ä»–å¼‚å¸¸å¹¶è½¬æ¢ä¸ºASRé”™è¯¯
        error_msg = f"éŸ³é¢‘æ•°æ®è¯†åˆ«æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
        logger.error(error_msg)
        raise ASRError(error_msg, "AUDIO_DATA_TRANSCRIPTION_ERROR", e)

def transcribe_base64_audio(base64_data: str,
                           model_name: str = "base",
                           language: Optional[str] = None,
                           task: str = "transcribe",
                           **kwargs) -> Dict[str, Any]:
    """
    ä»Base64ç¼–ç çš„éŸ³é¢‘æ•°æ®è¿›è¡Œè¯­éŸ³è¯†åˆ«
    
    Args:
        base64_data: Base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
        model_name: Whisperæ¨¡å‹åç§°
        language: è¯­è¨€ä»£ç  (å¦‚ 'zh', 'en')ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
        task: ä»»åŠ¡ç±»å‹ ('transcribe' æˆ– 'translate')
        **kwargs: å…¶ä»–Whisperå‚æ•°
    
    Returns:
        Dict[str, Any]: è¯†åˆ«ç»“æœ
    """
    try:
        # è¾“å…¥éªŒè¯
        if not base64_data or not isinstance(base64_data, str):
            raise ASRError("Base64æ•°æ®ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²", "INVALID_INPUT")
        
        logger.info("å¼€å§‹è§£ç Base64éŸ³é¢‘æ•°æ®...")
        
        # è§£ç Base64æ•°æ®
        try:
            audio_bytes = base64.b64decode(base64_data)
        except Exception as e:
            raise ASRError(f"Base64è§£ç å¤±è´¥: {str(e)}", "BASE64_DECODE_ERROR")
        
        # è°ƒç”¨éŸ³é¢‘æ•°æ®è¯†åˆ«å‡½æ•°
        result = transcribe_audio_data(
            audio_bytes,
            model_name=model_name,
            language=language,
            task=task,
            **kwargs
        )
        
        return result
        
    except ASRError:
        # é‡æ–°æŠ›å‡ºASRé”™è¯¯
        raise
    except Exception as e:
        # æ•è·å…¶ä»–å¼‚å¸¸å¹¶è½¬æ¢ä¸ºASRé”™è¯¯
        error_msg = f"Base64éŸ³é¢‘è¯†åˆ«æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
        logger.error(error_msg)
        raise ASRError(error_msg, "BASE64_TRANSCRIPTION_ERROR", e)

#---------------------------------------------------------------------

def get_asr_response_api(audio_input: Union[str, bytes, np.ndarray, str],
                         model_name: str = "base",
                         language: Optional[str] = None,
                         task: str = "transcribe",
                         sample_rate: Optional[int] = None,
                         **kwargs) -> Dict[str, Any]:
    """
    ä¸ºå‰ç«¯æä¾›çš„ASR APIæ¥å£ï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼
    
    Args:
        audio_input: éŸ³é¢‘è¾“å…¥ï¼Œå¯ä»¥æ˜¯ï¼š
            - str: æ–‡ä»¶è·¯å¾„æˆ–Base64ç¼–ç çš„å­—ç¬¦ä¸²
            - bytes: WAVæ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®
            - np.ndarray: éŸ³é¢‘numpyæ•°ç»„
        model_name: Whisperæ¨¡å‹åç§°
        language: è¯­è¨€ä»£ç 
        task: ä»»åŠ¡ç±»å‹ ('transcribe' æˆ– 'translate')
        sample_rate: é‡‡æ ·ç‡ï¼ˆä»…å½“audio_inputæ˜¯numpyæ•°ç»„æ—¶éœ€è¦ï¼‰
        **kwargs: å…¶ä»–Whisperå‚æ•°
    
    Returns:
        Dict[str, Any]: æ ‡å‡†åŒ–çš„APIå“åº”
    """
    try:
        # æ ¹æ®è¾“å…¥ç±»å‹é€‰æ‹©ç›¸åº”çš„å¤„ç†å‡½æ•°
        if isinstance(audio_input, str):
            # åˆ¤æ–­æ˜¯æ–‡ä»¶è·¯å¾„è¿˜æ˜¯Base64å­—ç¬¦ä¸²
            if os.path.exists(audio_input):
                # æ–‡ä»¶è·¯å¾„
                result = transcribe_audio_file(
                    audio_input,
                    model_name=model_name,
                    language=language,
                    task=task,
                    **kwargs
                )
            else:
                # Base64å­—ç¬¦ä¸²
                result = transcribe_base64_audio(
                    audio_input,
                    model_name=model_name,
                    language=language,
                    task=task,
                    **kwargs
                )
        elif isinstance(audio_input, bytes):
            # äºŒè¿›åˆ¶æ•°æ®
            result = transcribe_audio_data(
                audio_input,
                model_name=model_name,
                language=language,
                task=task,
                **kwargs
            )
        elif isinstance(audio_input, np.ndarray):
            # numpyæ•°ç»„
            result = transcribe_audio_data(
                audio_input,
                sample_rate=sample_rate,
                model_name=model_name,
                language=language,
                task=task,
                **kwargs
            )
        else:
            raise ASRError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {type(audio_input)}", "UNSUPPORTED_INPUT_TYPE")
        
        return result
        
    except ASRError as e:
        return {
            'success': False,
            'data': None,
            'error': {
                'code': e.error_code,
                'message': e.message,
                'type': 'ASRError'
            }
        }
    except Exception as e:
        return {
            'success': False,
            'data': None,
            'error': {
                'code': 'UNKNOWN_ERROR',
                'message': f"æœªçŸ¥é”™è¯¯: {str(e)}",
                'type': 'Exception'
            }
        }

def manage_asr_model(action: str, model_name: str = "base") -> Dict[str, Any]:
    """
    ç®¡ç†ASRæ¨¡å‹çš„APIæ¥å£
    
    Args:
        action: æ“ä½œç±»å‹ ('load', 'unload', 'reload', 'status')
        model_name: æ¨¡å‹åç§°ï¼ˆä»…åœ¨loadå’Œreloadæ—¶éœ€è¦ï¼‰
    
    Returns:
        Dict[str, Any]: æ“ä½œç»“æœ
    """
    try:
        if action == 'load':
            load_asr_model(model_name)
            return {
                'success': True,
                'message': f'Whisperæ¨¡å‹ {model_name} åŠ è½½æˆåŠŸ',
                'action': 'load'
            }
            
        elif action == 'unload':
            success = unload_asr_model()
            return {
                'success': success,
                'message': 'Whisperæ¨¡å‹é‡Šæ”¾æˆåŠŸ' if success else 'Whisperæ¨¡å‹é‡Šæ”¾å¤±è´¥',
                'action': 'unload'
            }
            
        elif action == 'reload':
            reload_asr_model(model_name)
            return {
                'success': True,
                'message': f'Whisperæ¨¡å‹ {model_name} é‡æ–°åŠ è½½æˆåŠŸ',
                'action': 'reload'
            }
            
        elif action == 'status':
            status = get_model_status()
            return {
                'success': True,
                'data': status,
                'action': 'status'
            }
            
        else:
            return {
                'success': False,
                'error': {
                    'code': 'INVALID_ACTION',
                    'message': f'æ— æ•ˆçš„æ“ä½œ: {action}ã€‚æ”¯æŒçš„æ“ä½œ: load, unload, reload, status',
                    'type': 'ValueError'
                }
            }
            
    except ASRError as e:
        return {
            'success': False,
            'error': {
                'code': e.error_code,
                'message': e.message,
                'type': 'ASRError'
            }
        }
    except Exception as e:
        return {
            'success': False,
            'error': {
                'code': 'UNKNOWN_ERROR',
                'message': f'æœªçŸ¥é”™è¯¯: {str(e)}',
                'type': 'Exception'
            }
        }

#---------------------------------------------------------------------

if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    
    print("=== ASRæµ‹è¯•å¼€å§‹ ===")
    print("æ³¨æ„ï¼šæ­¤æµ‹è¯•éœ€è¦æä¾›éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    print("ä½¿ç”¨ç¤ºä¾‹: python asr.py <audio_file_path>")
    
    import sys
    if len(sys.argv) > 1:
        audio_file = sys.argv[1]
        try:
            result = get_asr_response_api(audio_file)
            if result['success']:
                print(f"âœ… è¯†åˆ«æˆåŠŸ")
                print(f"ğŸ“ è¯†åˆ«æ–‡æœ¬: {result['data']['text']}")
                print(f"ğŸŒ æ£€æµ‹è¯­è¨€: {result['data']['language']}")
            else:
                print(f"âŒ è¯†åˆ«å¤±è´¥: {result['error']['message']}")
        except Exception as e:
            print(f"ğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
    else:
        print("è¯·æä¾›éŸ³é¢‘æ–‡ä»¶è·¯å¾„ä½œä¸ºå‚æ•°")

