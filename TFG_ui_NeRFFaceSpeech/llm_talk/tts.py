import torch
import io
import base64
import logging
from typing import Optional, Dict, Any
from chatterbox.mtl_tts import ChatterboxMultilingualTTS
import soundfile as sf
import numpy as np
import webrtcvad
import math

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
TTS_MODEL = None  # å»¶è¿ŸåŠ è½½

CLIP_DB = 1000 #å¥å°¾é™éŸ³è£å‰ªé˜ˆå€¼

#---------------------------------------------------------------------

class TTSError(Exception):
    """è‡ªå®šä¹‰TTSå¼‚å¸¸ç±»"""
    def __init__(self, message: str, error_code: str = None, original_error: Exception = None):
        self.message = message
        self.error_code = error_code
        self.original_error = original_error
        super().__init__(self.message)
        
#---------------------------------------------------------------------

def load_tts_model():
    """å»¶è¿ŸåŠ è½½TTSæ¨¡å‹"""
    global TTS_MODEL
    if TTS_MODEL is None:
        try:
            logger.info(f"æ­£åœ¨åŠ è½½TTSæ¨¡å‹åˆ°è®¾å¤‡: {DEVICE}")
            TTS_MODEL = ChatterboxMultilingualTTS.from_pretrained(DEVICE)
            logger.info("TTSæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            error_msg = f"TTSæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            raise TTSError(error_msg, "MODEL_LOAD_ERROR", e)
    return TTS_MODEL

def unload_tts_model():
    """
    ä»å†…å­˜ä¸­é‡Šæ”¾TTSæ¨¡å‹
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸé‡Šæ”¾
    """
    global TTS_MODEL
    try:
        if TTS_MODEL is not None:
            logger.info("æ­£åœ¨é‡Šæ”¾TTSæ¨¡å‹...")
            
            # å¦‚æœæ¨¡å‹æœ‰æ¸…ç†æ–¹æ³•ï¼Œè°ƒç”¨å®ƒ
            if hasattr(TTS_MODEL, 'cleanup'):
                TTS_MODEL.cleanup()
            elif hasattr(TTS_MODEL, 'close'):
                TTS_MODEL.close()
            
            # åˆ é™¤æ¨¡å‹å¼•ç”¨
            del TTS_MODEL
            TTS_MODEL = None
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()
            
            # å¦‚æœä½¿ç”¨CUDAï¼Œæ¸…ç†GPUå†…å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            
            logger.info("TTSæ¨¡å‹å·²æˆåŠŸé‡Šæ”¾")
            return True
        else:
            logger.info("TTSæ¨¡å‹æœªåŠ è½½ï¼Œæ— éœ€é‡Šæ”¾")
            return True
            
    except Exception as e:
        error_msg = f"TTSæ¨¡å‹é‡Šæ”¾å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        # å³ä½¿é‡Šæ”¾å¤±è´¥ï¼Œä¹Ÿå°è¯•é‡ç½®å…¨å±€å˜é‡
        TTS_MODEL = None
        return False

def reload_tts_model():
    """
    é‡æ–°åŠ è½½TTSæ¨¡å‹ï¼ˆå…ˆé‡Šæ”¾å†åŠ è½½ï¼‰
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸé‡æ–°åŠ è½½
    """
    try:
        logger.info("å¼€å§‹é‡æ–°åŠ è½½TTSæ¨¡å‹...")
        
        # å…ˆé‡Šæ”¾ç°æœ‰æ¨¡å‹
        unload_success = unload_tts_model()
        if not unload_success:
            logger.warning("æ¨¡å‹é‡Šæ”¾å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•é‡æ–°åŠ è½½")
        
        # é‡æ–°åŠ è½½æ¨¡å‹
        load_tts_model()
        
        logger.info("TTSæ¨¡å‹é‡æ–°åŠ è½½æˆåŠŸ")
        return True
        
    except Exception as e:
        error_msg = f"TTSæ¨¡å‹é‡æ–°åŠ è½½å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        raise TTSError(error_msg, "MODEL_RELOAD_ERROR", e)

def get_model_status():
    """
    è·å–TTSæ¨¡å‹çŠ¶æ€
    
    Returns:
        dict: æ¨¡å‹çŠ¶æ€ä¿¡æ¯
    """
    global TTS_MODEL
    
    status = {
        'loaded': TTS_MODEL is not None,
        'device': DEVICE,
        'cuda_available': torch.cuda.is_available(),
        'memory_info': {}
    }
    
    if TTS_MODEL is not None:
        status['model_type'] = type(TTS_MODEL).__name__
        
        # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
        if torch.cuda.is_available():
            status['memory_info'] = {
                'allocated': torch.cuda.memory_allocated(),
                'reserved': torch.cuda.memory_reserved(),
                'max_allocated': torch.cuda.max_memory_allocated(),
                'max_reserved': torch.cuda.max_memory_reserved()
            }
    
    return status

#---------------------------------------------------------------------

def wav_float_to_int16(wav: np.ndarray) -> np.ndarray:
    # å°† float æ³¢å½¢ (-1..1) è½¬ä¸º int16
    wav_i16 = (wav * 32767.0).astype(np.int16)
    return wav_i16

def vad_trim(wav: np.ndarray, sample_rate: int, aggressiveness: int = 2,
             frame_ms: int = 30, padding_ms: int = 300) -> np.ndarray:
    """
    ä½¿ç”¨ WebRTC VAD è£å‰ªå°¾éƒ¨éè¯­éŸ³ï¼ˆå¹¶ä¿ç•™å‰æ®µï¼‰
    aggressiveness: 0-3ï¼Œè¶Šé«˜è¶Šä¸¥æ ¼ï¼ˆæ›´å°‘å™ªéŸ³è¯¯åˆ¤ä¸ºè¯­éŸ³ï¼‰
    frame_ms: 10/20/30 å¸¸ç”¨
    padding_ms: ä¿ç•™å°¾éƒ¨çš„é¢å¤–æ¯«ç§’ï¼ˆé¿å…åˆ‡æ–­å°¾éŸ³ï¼‰
    """
    if wav.size == 0:
        return wav
    # ensure int16 PCM
    if np.issubdtype(wav.dtype, np.floating):
        wav_i16 = wav_float_to_int16(wav)
    else:
        wav_i16 = wav.astype(np.int16)

    vad = webrtcvad.Vad(aggressiveness)
    frame_bytes = int(sample_rate * (frame_ms / 1000.0))  # samples per frame
    byte_width = 2  # int16 -> 2 bytes
    step = frame_bytes
    n_frames = math.ceil(len(wav_i16) / step)

    is_speech = np.zeros(n_frames, dtype=bool)
    for i in range(n_frames):
        start = i * step
        end = min((i + 1) * step, len(wav_i16))
        frame = wav_i16[start:end]
        if len(frame) < frame_bytes:
            # pad
            frame = np.pad(frame, (0, frame_bytes - len(frame)), constant_values=0)
        raw_bytes = frame.tobytes()
        try:
            is_speech[i] = vad.is_speech(raw_bytes, sample_rate)
        except Exception:
            is_speech[i] = False

    non_speech_idx = np.where(is_speech)[0]
    if non_speech_idx.size == 0:
        # æ— æ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¿”å›åŸæ³¢å½¢
        return wav
    last_speech_frame = non_speech_idx[-1]
    # è®¡ç®—è¦ä¿ç•™åˆ°çš„æ ·æœ¬
    keep_samples = min(len(wav_i16), int((last_speech_frame + 1) * step + (padding_ms / 1000.0) * sample_rate))
    wav_trimmed = wav[:keep_samples]  # åŸ wav æ˜¯ float æˆ– int16ï¼Œéƒ½å¯ä»¥ç›´æ¥å‰ªåˆ‡ï¼ˆä¿æŒåŸ dtypeï¼‰
    # å°æ·¡å‡ºé¿å…çªå˜
    fade_len = int(0.03 * sample_rate)
    if fade_len*2 < len(wav_trimmed):
        window = np.linspace(1.0, 0.0, fade_len)
        wav_trimmed[-fade_len:] = wav_trimmed[-fade_len:] * window
    return wav_trimmed

#---------------------------------------------------------------------

def convert_text_to_wav_chatterbox(text: str,
                                 language_id: str = 'zh',
                                 audio_prompt_path: Optional[str] = None,
                                 exaggeration: float = 0.5,
                                 cfg_weight: float = 0.5,
                                 temperature: float = 0.8,
                                 repetition_penalty: float = 1.5,
                                 min_p: float = 0.05,
                                 top_p: float = 1
                                 ) -> Dict[str, Any]:
    """
    å°†æ–‡æœ¬è½¬æ¢ä¸ºWAVéŸ³é¢‘æ•°æ®ï¼Œè¿”å›å†…å­˜ä¸­çš„éŸ³é¢‘æ•°æ®
    
    Args:
        text: è¦è½¬æ¢çš„æ–‡æœ¬
        language_id: è¯­è¨€ID (é»˜è®¤'zh'ä¸­æ–‡)
        audio_prompt_path: éŸ³é¢‘æç¤ºæ–‡ä»¶è·¯å¾„
        exaggeration: å¤¸å¼ ç¨‹åº¦
        cfg_weight: CFGæƒé‡
        temperature: æ¸©åº¦å‚æ•°
        repetition_penalty: é‡å¤æƒ©ç½š
        min_p: æœ€å°æ¦‚ç‡
        top_p: é¡¶éƒ¨æ¦‚ç‡
        sample_rate: é‡‡æ ·ç‡
    
    Returns:
        Dict[str, Any]: åŒ…å«éŸ³é¢‘æ•°æ®çš„å­—å…¸
        {
            'success': bool,
            'data': {
                'wav_data': bytes,  # WAVæ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®
                'base64_data': str,  # Base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
                'sample_rate': int,  # é‡‡æ ·ç‡
                'duration': float,  # éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
                'text': str,  # åŸå§‹æ–‡æœ¬
                'audio_info': dict  # éŸ³é¢‘ä¿¡æ¯
            },
            'error': None or dict
        }
    """
    try:
        # è¾“å…¥éªŒè¯
        if not text or not isinstance(text, str):
            raise TTSError("æ–‡æœ¬ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²", "INVALID_INPUT")
        
        if len(text.strip()) == 0:
            raise TTSError("æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º", "EMPTY_TEXT")
        
        if len(text) > 1000:  # é™åˆ¶æ–‡æœ¬é•¿åº¦
            raise TTSError("æ–‡æœ¬é•¿åº¦è¶…è¿‡é™åˆ¶ï¼ˆ1000å­—ç¬¦ï¼‰", "TEXT_TOO_LONG")
        
        logger.info(f"å¼€å§‹TTSè½¬æ¢ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
        logger.info(f"å¼€å§‹TTSè½¬æ¢ï¼Œæ–‡æœ¬: {text[:100]}...")
        logger.info(f"è¯­è¨€ï¼š{language_id}")
        
        # åŠ è½½æ¨¡å‹
        model = load_tts_model()
        
        # ç”ŸæˆéŸ³é¢‘
        wav = model.generate(
            text,
            language_id=language_id,
            audio_prompt_path=audio_prompt_path,
            exaggeration=exaggeration,
            cfg_weight=cfg_weight,
            temperature=temperature,
            repetition_penalty=repetition_penalty,
            min_p=min_p,
            top_p=top_p
        )
        
        sample_rate = model.sr
        
        # éªŒè¯ç”Ÿæˆçš„éŸ³é¢‘
        if wav is None:
            raise TTSError("TTSæ¨¡å‹è¿”å›ç©ºéŸ³é¢‘", "EMPTY_AUDIO")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(wav, torch.Tensor):
            wav_np = wav.cpu().numpy()
        else:
            wav_np = np.array(wav)
        
        # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯1Dæ•°ç»„
        if wav_np.ndim > 1:
            wav_np = wav_np.flatten()
            
        # å¦‚æœæ˜¯ floatï¼Œç¡®ä¿èŒƒå›´åˆç†ï¼ˆ-1..1ï¼‰
        if np.issubdtype(wav_np.dtype, np.floating):
            max_abs = np.max(np.abs(wav_np)) if wav_np.size else 0.0
            if max_abs > 1.0:
                wav_np = wav_np / max_abs

        #trim
        try:
            wav_np = vad_trim(wav_np, sample_rate, aggressiveness=2)
        except Exception:
            # ä½¿ç”¨ç®€å•èƒ½é‡é˜ˆå€¼è£å‰ª
            energy = wav_np**2
            thresh = 1e-6  # æ ¹æ®ä½ çš„æ•°æ®è°ƒæ•´
            non_silent = np.where(energy > thresh)[0]
            if non_silent.size:
                wav_np = wav_np[:non_silent[-1]+1]
            else:
                wav_np = wav_np[:0]
        
        # è®¡ç®—éŸ³é¢‘æ—¶é•¿
        duration = len(wav_np) / sample_rate
        
        # åˆ›å»ºå†…å­˜ä¸­çš„WAVæ–‡ä»¶
        wav_buffer = io.BytesIO()
        sf.write(wav_buffer, wav_np, sample_rate, format='WAV')
        wav_data = wav_buffer.getvalue()
        wav_buffer.close()
        
        # è½¬æ¢ä¸ºBase64ç¼–ç 
        base64_data = base64.b64encode(wav_data).decode('utf-8')
        
        # éŸ³é¢‘ä¿¡æ¯
        audio_info = {
            'sample_rate': sample_rate,
            'duration': duration,
            'channels': 1,
            'samples': len(wav_np),
            'format': 'WAV',
            'bit_depth': 16
        }
        
        logger.info(f"TTSè½¬æ¢æˆåŠŸï¼ŒéŸ³é¢‘æ—¶é•¿: {duration:.2f}ç§’")
        
        return {
            'success': True,
            'data': {
                'wav_data': wav_data,
                'base64_data': base64_data,
                'sample_rate': sample_rate,
                'duration': duration,
                'text': text,
                'audio_info': audio_info
            },
            'error': None
        }
        
    except TTSError:
        # é‡æ–°æŠ›å‡ºTTSé”™è¯¯
        raise
    except Exception as e:
        # æ•è·å…¶ä»–å¼‚å¸¸å¹¶è½¬æ¢ä¸ºTTSé”™è¯¯
        error_msg = f"TTSè½¬æ¢æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
        logger.error(error_msg)
        raise TTSError(error_msg, "TTS_CONVERSION_ERROR", e)

#---------------------------------------------------------------------
    
def get_tts_response_api(text: str, **kwargs) -> Dict[str, Any]:
    """
    ä¸ºå‰ç«¯æä¾›çš„TTS APIæ¥å£ï¼Œè¿”å›æ ‡å‡†åŒ–çš„å“åº”æ ¼å¼
    
    Args:
        text: è¦è½¬æ¢çš„æ–‡æœ¬
        **kwargs: å…¶ä»–TTSå‚æ•°
    
    Returns:
        Dict[str, Any]: æ ‡å‡†åŒ–çš„APIå“åº”
    """
    try:
        result = convert_text_to_wav_chatterbox(text, **kwargs)
        return result
    except TTSError as e:
        return {
            'success': False,
            'data': None,
            'error': {
                'code': e.error_code,
                'message': e.message,
                'type': 'TTSError'
            }
        }
    except Exception as e:
        return {
            'success': False,
            'data': None,
            'error': {
                'code': 'UNKNOWN_ERROR',
                'message': f"æœªçŸ¥é”™è¯¯: {str(e)}",
                'type': 'Exception'
            }
        }

def save_wav_to_file(wav_data: bytes, file_path: str) -> bool:
    """
    å°†WAVæ•°æ®ä¿å­˜åˆ°æ–‡ä»¶
    
    Args:
        wav_data: WAVäºŒè¿›åˆ¶æ•°æ®
        file_path: ä¿å­˜è·¯å¾„
    
    Returns:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    try:
        with open(file_path, 'wb') as f:
            f.write(wav_data)
        logger.info(f"WAVæ–‡ä»¶å·²ä¿å­˜åˆ°: {file_path}")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜WAVæ–‡ä»¶å¤±è´¥: {str(e)}")
        return False

def manage_tts_model(action: str) -> Dict[str, Any]:
    """
    ç®¡ç†TTSæ¨¡å‹çš„APIæ¥å£
    
    Args:
        action: æ“ä½œç±»å‹ ('load', 'unload', 'reload', 'status')
    
    Returns:
        Dict[str, Any]: æ“ä½œç»“æœ
    """
    try:
        if action == 'load':
            load_tts_model()
            return {
                'success': True,
                'message': 'TTSæ¨¡å‹åŠ è½½æˆåŠŸ',
                'action': 'load'
            }
            
        elif action == 'unload':
            success = unload_tts_model()
            return {
                'success': success,
                'message': 'TTSæ¨¡å‹é‡Šæ”¾æˆåŠŸ' if success else 'TTSæ¨¡å‹é‡Šæ”¾å¤±è´¥',
                'action': 'unload'
            }
            
        elif action == 'reload':
            reload_tts_model()
            return {
                'success': True,
                'message': 'TTSæ¨¡å‹é‡æ–°åŠ è½½æˆåŠŸ',
                'action': 'reload'
            }
            
        elif action == 'status':
            status = get_model_status()
            return {
                'success': True,
                'data': status,
                'action': 'status'
            }
            
        else:
            return {
                'success': False,
                'error': {
                    'code': 'INVALID_ACTION',
                    'message': f'æ— æ•ˆçš„æ“ä½œ: {action}ã€‚æ”¯æŒçš„æ“ä½œ: load, unload, reload, status',
                    'type': 'ValueError'
                }
            }
            
    except TTSError as e:
        return {
            'success': False,
            'error': {
                'code': e.error_code,
                'message': e.message,
                'type': 'TTSError'
            }
        }
    except Exception as e:
        return {
            'success': False,
            'error': {
                'code': 'UNKNOWN_ERROR',
                'message': f'æœªçŸ¥é”™è¯¯: {str(e)}',
                'type': 'Exception'
            }
        }
    
#---------------------------------------------------------------------

if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.DEBUG)
    
    # æµ‹è¯•ç”¨ä¾‹
    test_text = "äººå·¥æ™ºèƒ½å‘å±•ç®€å²"
    
    model = ChatterboxMultilingualTTS.from_pretrained('cuda')
    
    wav = model.generate(
        test_text,
        language_id='zh',
    )
    
    
    sf.write(
        './test_d.wav',
        wav.squeeze().cpu().numpy(),
        model.sr
    )
    
    # print("=== TTSæµ‹è¯•å¼€å§‹ ===")
    # try:
    #     # æµ‹è¯•1: æ¨¡å‹çŠ¶æ€æ£€æŸ¥
    #     print("\n--- æµ‹è¯•1: æ¨¡å‹çŠ¶æ€æ£€æŸ¥ ---")
    #     status_result = manage_tts_model('status')
    #     if status_result['success']:
    #         print(f"âœ… æ¨¡å‹çŠ¶æ€: {status_result['data']}")
    #     else:
    #         print(f"âŒ çŠ¶æ€æ£€æŸ¥å¤±è´¥: {status_result['error']['message']}")
        
    #     # æµ‹è¯•2: TTSè½¬æ¢
    #     print("\n--- æµ‹è¯•2: TTSè½¬æ¢ ---")
    #     result = get_tts_response_api(test_text)
        
    #     if result['success']:
    #         print(f"âœ… TTSè½¬æ¢æˆåŠŸ")
    #         print(f"ğŸ“ åŸå§‹æ–‡æœ¬: {result['data']['text']}")
    #         print(f"ğŸµ éŸ³é¢‘æ—¶é•¿: {result['data']['duration']:.2f}ç§’")
    #         print(f"ğŸ“Š é‡‡æ ·ç‡: {result['data']['sample_rate']}Hz")
    #         print(f"ğŸ“ éŸ³é¢‘ä¿¡æ¯: {result['data']['audio_info']}")
    #         print(f"ğŸ’¾ WAVæ•°æ®å¤§å°: {len(result['data']['wav_data'])} bytes")
    #         print(f"ğŸ”¤ Base64æ•°æ®é•¿åº¦: {len(result['data']['base64_data'])} å­—ç¬¦")

    #         save_wav_to_file(result['data']['wav_data'], 'test_output.wav')
    #         print("ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜åˆ° test_output.wav")
            
    #     else:
    #         print(f"âŒ TTSè½¬æ¢å¤±è´¥: {result['error']['message']}")
        
    #     # æµ‹è¯•3: æ¨¡å‹é‡Šæ”¾
    #     print("\n--- æµ‹è¯•3: æ¨¡å‹é‡Šæ”¾ ---")
    #     unload_result = manage_tts_model('unload')
    #     if unload_result['success']:
    #         print(f"âœ… {unload_result['message']}")
    #     else:
    #         print(f"âŒ æ¨¡å‹é‡Šæ”¾å¤±è´¥: {unload_result['error']['message']}")
        
    #     # æµ‹è¯•4: æ¨¡å‹é‡æ–°åŠ è½½
    #     print("\n--- æµ‹è¯•4: æ¨¡å‹é‡æ–°åŠ è½½ ---")
    #     reload_result = manage_tts_model('reload')
    #     if reload_result['success']:
    #         print(f"âœ… {reload_result['message']}")
    #     else:
    #         print(f"âŒ æ¨¡å‹é‡æ–°åŠ è½½å¤±è´¥: {reload_result['error']['message']}")
        
    #     # æµ‹è¯•5: é‡æ–°æ£€æŸ¥çŠ¶æ€
    #     print("\n--- æµ‹è¯•5: é‡æ–°æ£€æŸ¥çŠ¶æ€ ---")
    #     final_status = manage_tts_model('status')
    #     if final_status['success']:
    #         print(f"âœ… æœ€ç»ˆæ¨¡å‹çŠ¶æ€: {final_status['data']}")
    #     else:
    #         print(f"âŒ çŠ¶æ€æ£€æŸ¥å¤±è´¥: {final_status['error']['message']}")
            
    # except Exception as e:
    #     print(f"ğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
    
    # print("\n=== TTSæµ‹è¯•ç»“æŸ ===")